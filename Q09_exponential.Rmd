---
title: "Quizz 9: Exponential"
output:
  html_document:
    df_print: paged
---

------------------------------

[Back to Index](Q_index.html)

------------------------------


## Bus waiting times:
For Questions 1-3, refer to the bus waiting time example from the lesson.

### Queston 1

Recall that we used the conjugate gamma prior for $\lambda$, the arrival rate in buses per minute. Suppose our prior belief about this rate is that it should have mean 1/20 arrivals per minute with standard deviation 1/5. Then the prior is \text{Gamma}(a, b) with $a=1/16$.

Find the value of $b$. Round your answer to two decimal places.


```{r}
a = 1/16
prior.mean = 1/20

b = a/prior.mean
b

```

### Question 2

Suppose that we wish to use a prior with the same mean (1/20), but with effective sample size of one arrival. Then the prior for $\lambda$ is \text{Gamma}(1, 20)Gamma(1,20).

In addition to the original $Y_1=12$, we observe the waiting times for four additional buses: $Y_2=15$, $Y_3=8$, $Y_4=13.5$, $Y_5=25$.

Recall that with multiple (independent) observations, the posterior for $\lambda$ is \text{Gamma}(\alpha, \beta) where $\alpha = a + n$ and $\beta = b + \sum y_i$.

What is the posterior mean for $\lambda$? Round your answer to two decimal places.

```{r}
a = 1
b = 20
Y = c(12, 15, 8, 13.5, 25)
n = length(Y)

a.post = a + n
a.post
b.post = b + sum(Y)
b.post

posterior.mean = a.post / b.post
round(posterior.mean, 2)
```

### Question 3

Continuing Question 2, use R or Excel to find the posterior probability that $\lambda < 1/10$? Round your answer to two decimal places.

```{r}
lambda = 1/10
p.lambda = pgamma(lambda, a.post, b.post)
round(p.lambda, 2)
```

```{r}
lambda = seq(0, 0.4, .01)

plot(lambda, dgamma(lambda, a, b), type='l', lty=1, lwd=2, col='darkblue')
lines(lambda, dgamma(lambda, a.post, b.post), col='darkorange', lty=2, lwd=2)
title("Distribution of lambda for bus waiting times")
legend(0.57, 20, legend = c("prior Gamma(1, 5)", "posterior Gamma(6, 93.5)"), col=c("darkblue", "darkorange"), lty=c(1, 2), lwd=2)
abline(v=0.1, col="grey", lty=3, lwd=1.5)

```



## Earthquake Data

For Questions 4-10, consider the following earthquake data:

The United States Geological Survey maintains a list of significant earthquakes worldwide. We will model the rate of earthquakes of magnitude 4.0+ in the state of California during 2015. An iid exponential model on the waiting time between significant earthquakes is appropriate if we assume:

- earthquake events are independent,
- the rate at which earthquakes occur does not change during the year, and
- the earthquake hazard rate does not change (i.e., the probability of an earthquake happening tomorrow is constant regardless of whether the previous earthquake was yesterday or 100 days ago).

Let $Y_i$ denote the waiting time in days between the ith earthquake and the following earthquake. Our model is $Y_i \overset{\text{iid}}{\sim} \text{Exponential}(\lambda)$ where the expected waiting time between earthquakes is $E(Y) = 1/\lambda$ days.

Assume the conjugate prior $\lambda \sim \text{Gamma}(a,b)$. Suppose our prior expectation for $\lambda$ is 1/30, and we wish to use a prior effective sample size of one interval between earthquakes.


### Question 4
What is the value of $a$?

**In exponential-gamma model $a$ is the effective sample size**. Therefore $a=1$.

See [Earhtquake Data Example](https://rpubs.com/army_aviator/370794)



### Question 5
What is the value of $b$?

Prior mean is $1/30$ and $a = 1$, then $b=30$


```{r}
a = 1
b = 30
lambda = seq(0, 1, .01)
curve(dgamma(x, shape = a, rate = b), lty=1, lwd=2, col='darkblue',
      xlab = expression(lambda), ylab = "Prior Distribution",
      main = "Earthquake waiting Times")

legend_labels = c(expression(prior ~ Gamma(1, 30)))

legend(0.7, 30, legend = legend_labels, col=c("darkblue"), lty=c(1, 2), lwd=2)
```

Gamma distribution with $\alpha = 1$ and $\beta = 30$ is equivalent Exponential with rate $\lambda = 1/30$

Given a r.v. $X\sim Exp(X)$:

* $E[X] = 1/\lambda$
* $Var(X) = 1/\lambda^2$

In this example for prior $lambda$, $E[\lambda] = 0.033$ and $Var(\lambda) = 0.001$

```{r}
X = seq(0, 200, 1)
plot(X,
     dexp(X, rate = 1/30),
     type='l', lty=1, lwd=2, col="cyan",
     xlab = expression(Y ~ (minutes)), ylab = "Likelihood",
     main = expression(Likelihood ~ f(Y ~"|"~ lambda ~ "= 1/30"))
     )
legend(155, 0.033, legend = "Exp(1/30)", col = "cyan", lty=1)

```



### Question 6

The significant earthquakes of magnitude 4.0+ in the state of California during 2015 occurred on the following dates [http://earthquake.usgs.gov/earthquakes/browse/significant.php?year=2015](http://earthquake.usgs.gov/earthquakes/browse/significant.php?year=2015):

January 4, January 20, January 28, May 22, July 21, July 25, August 17, September 16, December 30.

Recall that we are modeling the waiting times between earthquakes in days. Which of the following is our data vector?
1 point

1. **y = (16, 8, 114, 60, 4, 23, 30, 105)**
2. y = (0, 0, 4, 2, 0, 1, 1, 3)
3. y = (3, 16, 8, 114, 60, 4, 23, 30, 105)
4. y = (3, 16, 8, 114, 60, 4, 23, 30, 105, 1)

```{r}
Y = c(16, 8, 114, 60, 4, 23, 30, 105)
Y
```


**Note**:
We are modeling the waiting times between earthquakes in days. There are eight intervals between the first and last event. We are excluding four days of the year in which no events were observed. A more comprehensive model (e.g., censoring methods) would account for the fact that there were no major earthquakes Jan. 1 to Jan. 4 and Dec. 30 to Dec. 31. This is beyond the scope of this tutorial. [[Source](https://rpubs.com/army_aviator/370794)]


### Question 7


Having observed data $Y = \{y_1, \cdots, y_n \}$, 
for **Exponential likelihood** and **Gamma prior** the posterior is:

$\lambda \mid Y \sim  Gamma(\alpha + n,~ \beta + \sum{y_i} )$

What is the value of $\alpha$?

```{r}
a.post = a + length(Y)
a.post
```

### Question 8

What is the value of $\beta$?

```{r}
b.post = b + sum(Y)
b.post
```


### Question 9

Use R or Excel to calculate the upper end of the 95% equal-tailed credible interval for $\lambda$, the rate of major earthquakes in events per day. Round your answer to two decimal places.

```{r}
qgamma(p =.975, shape=a.post, rate=b.post)
```



```{r}
lambda = seq(0, 01, 0.01)
plot(lambda, dgamma(lambda, shape = a.post, rate = b.post), type = "l", lty=2, lwd=2, col='darkorange',
      xlab = expression(lambda), ylab = "Distribution",
      main = "Earthquake Waiting Times")

lines(lambda, dgamma(lambda, shape = a, rate = b), lty=1, lwd=2, col='darkblue')

legend_labels = c(expression(post. ~ Gamma(9, 390)),
                  expression(prior ~ Gamma(1, 30)))

legend(0.68, 55, legend = legend_labels, col=c("darkorange", "darkblue"), lty=c(1, 2), lwd=2)
```



### Question 10

The posterior predictive density for a new waiting time $y^*$ in days is:

$f(y^* \mid \mathbf{y} ) = \int f(y^* \mid \lambda) \cdot f(\lambda \mid \mathbf{y}) d\lambda = \frac{ \beta^\alpha \Gamma(\alpha + 1) }{ (\beta + y^*)^{\alpha + 1} \Gamma(\alpha) } I_{\{y^* \ge 0 \}} = \frac{ \beta^\alpha \alpha}{ (\beta + y^*)^{\alpha + 1}} I_{\{y^* \ge 0 \}}$
 
where $f(\lambda \mid \mathbf{y})$ is the $\text{Gamma}(\alpha, \beta)$ posterior found earlier. Use R or Excel to evaluate this posterior predictive PDF.

Which of the following graphs shows the posterior predictive distribution for $y^*$
 
 
```{r}
post.pred.dist <- function(x, a, b){
  y = ((b^a) * a) / ((b + x)^(a+1))
  return(y)
}

x = seq(1, 120)
plot(x, post.pred.dist(x, a.post, b.post), type='l', lty=1, lwd=2, col='green',
     xlab = expression(Y^"*"),  ylab = "Posterior Predictive Distribution",
     main = "Predicting Future Earthquake Waiting Times")

```
 
 
 
 
------------------------------

[Back to Index](Q_index.html)

------------------------------
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

